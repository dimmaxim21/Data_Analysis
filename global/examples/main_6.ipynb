{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nPerplexity  792.412475586\n"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "import artm\n",
    "from multiprocessing import cpu_count\n",
    "from os import getcwd\n",
    "\n",
    "topics = 10\n",
    "d_path = getcwd() + \"/LWs/LW_13/data/lenta.txt\"\n",
    "batch_vectorizer = artm.BatchVectorizer(data_path=d_path, data_format=\"vowpal_wabbit\", target_folder=\"batch_vectorizer_target_folder\", batch_size=10)\n",
    "topic_names = [\"topic#1\" + str(i) for i in range(topics - 1)] + [\"bcg\"]\n",
    "dictionary = artm.Dictionary(\"dictionary\")\n",
    "dictionary.gather(batch_vectorizer.data_path)\n",
    "model_lda = artm.LDA(num_topics=topics, num_processors=cpu_count(), cache_theta=True, num_document_passes=1)\n",
    "model_lda.initialize(dictionary=dictionary)\n",
    "model_lda.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=50)\n",
    "print \"\\nPerplexity \", model_lda.perplexity_last_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nPerplexity  336.208709717\n"
     ]
    }
   ],
   "source": [
    "dictionary = artm.Dictionary(\"dictionary\")\n",
    "dictionary.gather(batch_vectorizer.data_path)\n",
    "model_lda = artm.LDA(num_topics=topics, num_processors=cpu_count(), cache_theta=True, num_document_passes=1, alpha=0.5,\n",
    "                     beta=-0.5)\n",
    "model_lda.initialize(dictionary=dictionary)\n",
    "model_lda.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=50)\n",
    "print \"\\nPerplexity \", model_lda.perplexity_last_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nPerplexity  291.809509277\n"
     ]
    }
   ],
   "source": [
    "dictionary = artm.Dictionary(\"dictionary\")\n",
    "dictionary.gather(batch_vectorizer.data_path)\n",
    "model_lda = artm.LDA(num_topics=topics, num_processors=cpu_count(), cache_theta=True, num_document_passes=1, alpha=-0.5,\n",
    "                     beta=-0.5)\n",
    "model_lda.initialize(dictionary=dictionary)\n",
    "model_lda.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=50)\n",
    "print \"\\nPerplexity \", model_lda.perplexity_last_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nPerplexity  116.821495056\n"
     ]
    }
   ],
   "source": [
    "dictionary = artm.Dictionary(\"dictionary\")\n",
    "dictionary.gather(batch_vectorizer.data_path)\n",
    "model_lda = artm.LDA(num_topics=topics, num_processors=cpu_count(), cache_theta=True, num_document_passes=1, alpha=0.5,\n",
    "                     beta=-2)\n",
    "model_lda.initialize(dictionary=dictionary)\n",
    "model_lda.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=50)\n",
    "print \"\\nPerplexity \", model_lda.perplexity_last_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nPerplexity  1670.98303223\n"
     ]
    }
   ],
   "source": [
    "dictionary = artm.Dictionary(\"dictionary\")\n",
    "dictionary.gather(batch_vectorizer.data_path)\n",
    "model_lda = artm.LDA(num_topics=topics, num_processors=cpu_count(), cache_theta=True, num_document_passes=1, alpha=2.5,\n",
    "                     beta=0.5)\n",
    "model_lda.initialize(dictionary=dictionary)\n",
    "model_lda.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=50)\n",
    "print \"\\nPerplexity \", model_lda.perplexity_last_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nPerplexity  239.111831665\n"
     ]
    }
   ],
   "source": [
    "dictionary = artm.Dictionary(\"dictionary\")\n",
    "dictionary.gather(batch_vectorizer.data_path)\n",
    "model_lda = artm.LDA(num_topics=topics, num_processors=cpu_count(), cache_theta=True, num_document_passes=1, alpha=-2.5,\n",
    "                     beta=-0.5)\n",
    "model_lda.initialize(dictionary=dictionary)\n",
    "model_lda.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=50)\n",
    "print \"\\nPerplexity \", model_lda.perplexity_last_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nPerplexity  664.595458984\n"
     ]
    }
   ],
   "source": [
    "dictionary = artm.Dictionary(\"dictionary\")\n",
    "dictionary.gather(batch_vectorizer.data_path)\n",
    "model_lda = artm.LDA(num_topics=topics, num_processors=cpu_count(), cache_theta=True, num_document_passes=1, alpha=0.001,\n",
    "                     beta=0.001)\n",
    "model_lda.initialize(dictionary=dictionary)\n",
    "model_lda.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=50)\n",
    "print \"\\nPerplexity \", model_lda.perplexity_last_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nPerplexity  119.767295837\n"
     ]
    }
   ],
   "source": [
    "dictionary = artm.Dictionary(\"dictionary\")\n",
    "dictionary.gather(batch_vectorizer.data_path)\n",
    "model_lda = artm.LDA(num_topics=topics, num_processors=cpu_count(), cache_theta=True, num_document_passes=1, alpha=-5,\n",
    "                     beta=-5)\n",
    "model_lda.initialize(dictionary=dictionary)\n",
    "model_lda.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=50)\n",
    "print \"\\nPerplexity \", model_lda.perplexity_last_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nPerplexity  118.149421692\n"
     ]
    }
   ],
   "source": [
    "dictionary = artm.Dictionary(\"dictionary\")\n",
    "dictionary.gather(batch_vectorizer.data_path)\n",
    "model_lda = artm.LDA(num_topics=topics, num_processors=cpu_count(), cache_theta=True, num_document_passes=3, alpha=0.5,\n",
    "                     beta=-2)\n",
    "model_lda.initialize(dictionary=dictionary)\n",
    "model_lda.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=50)\n",
    "print \"\\nPerplexity \", model_lda.perplexity_last_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nPerplexity  119.831489563\n"
     ]
    }
   ],
   "source": [
    "dictionary = artm.Dictionary(\"dictionary\")\n",
    "dictionary.gather(batch_vectorizer.data_path)\n",
    "model_lda = artm.LDA(num_topics=topics, num_processors=cpu_count(), cache_theta=True, num_document_passes=5, alpha=0.5,\n",
    "                     beta=-2)\n",
    "model_lda.initialize(dictionary=dictionary)\n",
    "model_lda.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=50)\n",
    "print \"\\nPerplexity \", model_lda.perplexity_last_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nPerplexity  124.524841309\n"
     ]
    }
   ],
   "source": [
    "dictionary = artm.Dictionary(\"dictionary\")\n",
    "dictionary.gather(batch_vectorizer.data_path)\n",
    "model_lda = artm.LDA(num_topics=topics, num_processors=cpu_count(), cache_theta=True, num_document_passes=10, alpha=0.5,\n",
    "                     beta=-2)\n",
    "model_lda.initialize(dictionary=dictionary)\n",
    "model_lda.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=50)\n",
    "print \"\\nPerplexity \", model_lda.perplexity_last_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidOperationException",
     "evalue": "Dictionary 'dictionary' does not exist",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mInvalidOperationException\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-68b5688d1b05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m model_lda = artm.LDA(num_topics=topics, num_processors=cpu_count(), cache_theta=True, num_document_passes=10, alpha=0.5,\n\u001b[1;32m      4\u001b[0m                      beta=-1.5)\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel_lda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmodel_lda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_offline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_vectorizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_vectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_collection_passes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"\\nPerplexity \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_lda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperplexity_last_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/bigartm-0.9.0-py2.7.egg/artm/lda_model.pyc\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(self, dictionary)\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_perp_score_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'p_wt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/bigartm-0.9.0-py2.7.egg/artm/artm_model.pyc\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(self, dictionary)\u001b[0m\n\u001b[1;32m   1020\u001b[0m                                      \u001b[0mdictionary_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdictionary_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m                                      \u001b[0mtopic_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_topic_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m                                      seed=self._seed)\n\u001b[0m\u001b[1;32m   1023\u001b[0m         self.master.initialize_model(model_name=self.model_nwt,\n\u001b[1;32m   1024\u001b[0m                                      \u001b[0mdictionary_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdictionary_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/bigartm-0.9.0-py2.7.egg/artm/master_component.pyc\u001b[0m in \u001b[0;36minitialize_model\u001b[0;34m(self, model_name, topic_names, dictionary_name, seed, args)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0minit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdictionary_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdictionary_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArtmInitializeModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaster_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclear_theta_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/bigartm-0.9.0-py2.7.egg/artm/wrapper/api.pyc\u001b[0m in \u001b[0;36martm_api_call\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mc_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;31m# return result value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/bigartm-0.9.0-py2.7.egg/artm/wrapper/api.pyc\u001b[0m in \u001b[0;36m_check_error\u001b[0;34m(self, error_code)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mexception_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mARTM_EXCEPTION_BY_CODE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mexception_class\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidOperationException\u001b[0m: Dictionary 'dictionary' does not exist"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "dictionary = artm.Dictionary(\"dictionary\")\n",
    "dictionary.gather(batch_vectorizer.data_path)\n",
    "model_lda = artm.LDA(num_topics=topics, num_processors=cpu_count(), cache_theta=True, num_document_passes=10, alpha=0.5,\n",
    "                     beta=-1.5)\n",
    "model_lda.initialize(dictionary=dictionary)\n",
    "model_lda.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=50)\n",
    "print \"\\nPerplexity \", model_lda.perplexity_last_value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
